>> a4_main(300,0,0,0)
For the training data, the classification cross-entropy loss is 2.357111, and the classification error rate (i.e. the misclassification rate) is 0.878000
For the validation data, the classification cross-entropy loss is 2.360736, and the classification error rate (i.e. the misclassification rate) is 0.877000
For the test data, the classification cross-entropy loss is 2.358583, and the classification error rate (i.e. the misclassification rate) is 0.879889

>> describe_matrix(visible_state_to_hidden_probabilities(test_rbm_w, data_37_cases))
Describing a matrix of size 100 by 37. The mean of the elements is 0.466207. The sum of the elements is 1724.967611

>> describe_matrix(hidden_state_to_visible_probabilities(test_rbm_w, test_hidden_state_37_cases))
Describing a matrix of size 256 by 37. The mean of the elements is 0.463595. The sum of the elements is 4391.169583

>> configuration_goodness(test_rbm_w, data_37_cases, test_hidden_state_37_cases)
m =  37
ans = -18.391

>> describe_matrix(configuration_goodness_gradient(data_37_cases, test_hidden_state_37_cases))
Describing a matrix of size 100 by 256. The mean of the elements is 0.123680. The sum of the elements is 3166.216216

>> describe_matrix(cd1(test_rbm_w, data_37_cases))
sample_bernoulli() was called with a matrix of size 100 by 37. sample_bernoulli() was called with a matrix of size 256 by 37. 
sample_bernoulli() was called with a matrix of size 100 by 37. 
Describing a matrix of size 100 by 256. The mean of the elements is -0.182409. The sum of the elements is -4669.675676

>> describe_matrix(cd1(test_rbm_w, data_37_cases))
sample_bernoulli() was called with a matrix of size 100 by 37. sample_bernoulli() was called with a matrix of size 256 by 37. 
Describing a matrix of size 100 by 256. The mean of the elements is -0.184222. The sum of the elements is -4716.094972

>> a4_main(300, .02, .005, 1000)
For the training data, the classification cross-entropy loss is 0.258886, and the classification error rate (i.e. the misclassification rate) is 0.049000
For the validation data, the classification cross-entropy loss is 0.322890, and the classification error rate (i.e. the misclassification rate) is 0.076000
For the test data, the classification cross-entropy loss is 0.339875, and the classification error rate (i.e. the misclassification rate) is 0.086778
>> a4_main(300, .02, .001, 1000)
For the training data, the classification cross-entropy loss is 0.627320, and the classification error rate (i.e. the misclassification rate) is 0.120000
For the validation data, the classification cross-entropy loss is 0.673805, and the classification error rate (i.e. the misclassification rate) is 0.129000
For the test data, the classification cross-entropy loss is 0.668939, and the classification error rate (i.e. the misclassification rate) is 0.136333
>> a4_main(300, .02, .01, 1000)
For the training data, the classification cross-entropy loss is 0.174498, and the classification error rate (i.e. the misclassification rate) is 0.026000
For the validation data, the classification cross-entropy loss is 0.259159, and the classification error rate (i.e. the misclassification rate) is 0.071000
For the test data, the classification cross-entropy loss is 0.280291, and the classification error rate (i.e. the misclassification rate) is 0.077667
>> a4_main(300, .02, .05, 1000)
For the training data, the classification cross-entropy loss is 0.050874, and the classification error rate (i.e. the misclassification rate) is 0.001000
For the validation data, the classification cross-entropy loss is 0.202482, and the classification error rate (i.e. the misclassification rate) is 0.060000
For the test data, the classification cross-entropy loss is 0.226878, and the classification error rate (i.e. the misclassification rate) is 0.067333
>> a4_main(300, .02, .1, 1000)
For the training data, the classification cross-entropy loss is 0.025921, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 0.198644, and the classification error rate (i.e. the misclassification rate) is 0.059000
For the test data, the classification cross-entropy loss is 0.225950, and the classification error rate (i.e. the misclassification rate) is 0.065889
>> a4_main(300, .02, .5, 1000)
For the training data, the classification cross-entropy loss is 0.004919, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 0.224757, and the classification error rate (i.e. the misclassification rate) is 0.055000
For the test data, the classification cross-entropy loss is 0.260087, and the classification error rate (i.e. the misclassification rate) is 0.065444
>> a4_main(300, .02, 1, 1000)
For the training data, the classification cross-entropy loss is 0.001858, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 0.272533, and the classification error rate (i.e. the misclassification rate) is 0.060000
For the test data, the classification cross-entropy loss is 0.312369, and the classification error rate (i.e. the misclassification rate) is 0.067889
>> a4_main(300, .02, 2, 1000)
For the training data, the classification cross-entropy loss is 0.000083, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 0.578923, and the classification error rate (i.e. the misclassification rate) is 0.070000
For the test data, the classification cross-entropy loss is 0.670388, and the classification error rate (i.e. the misclassification rate) is 0.076333
>> a4_main(300, .02, 4, 1000)
For the training data, the classification cross-entropy loss is 0.000008, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 1.306495, and the classification error rate (i.e. the misclassification rate) is 0.076000
For the test data, the classification cross-entropy loss is 1.478573, and the classification error rate (i.e. the misclassification rate) is 0.082333
>> a4_main(300, .02, .75, 1000)
For the training data, the classification cross-entropy loss is 0.003027, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 0.244287, and the classification error rate (i.e. the misclassification rate) is 0.055000
For the test data, the classification cross-entropy loss is 0.281627, and the classification error rate (i.e. the misclassification rate) is 0.066778
>> a4_main(300, .02, .8, 1000)
For the training data, the classification cross-entropy loss is 0.002761, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 0.248909, and the classification error rate (i.e. the misclassification rate) is 0.057000
For the test data, the classification cross-entropy loss is 0.286602, and the classification error rate (i.e. the misclassification rate) is 0.067111
>> a4_main(300, .02, .7, 1000)
For the training data, the classification cross-entropy loss is 0.003313, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 0.240096, and the classification error rate (i.e. the misclassification rate) is 0.054000
For the test data, the classification cross-entropy loss is 0.277077, and the classification error rate (i.e. the misclassification rate) is 0.066556
>> a4_main(300, .02, .65, 1000)
For the training data, the classification cross-entropy loss is 0.003632, and the classification error rate (i.e. the misclassification rate) is 0.000000
For the validation data, the classification cross-entropy loss is 0.236109, and the classification error rate (i.e. the misclassification rate) is 0.055000
For the test data, the classification cross-entropy loss is 0.272731, and the classification error rate (i.e. the misclassification rate) is 0.066333
